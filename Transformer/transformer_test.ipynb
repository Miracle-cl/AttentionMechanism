{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from preprocess import Lang\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1790 2097\n",
      "135842\n"
     ]
    }
   ],
   "source": [
    "with open('result_0326.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "print(data['eng_lang'].n_words, data['fra_lang'].n_words)\n",
    "filter_tokenize = data['token']\n",
    "\n",
    "fra_token, eng_token = zip(*filter_tokenize)\n",
    "print(len(fra_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[2, 4, 5, 3], [2, 4, 5, 3]],\n",
       " [[2, 6, 5, 3], [2, 6, 7, 3]],\n",
       " [[2, 1, 5, 3], [2, 6, 7, 3]]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['token'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135842"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.312686797897557,\n",
       " 3.160561893345268,\n",
       " 65,\n",
       " 9.58004151882334,\n",
       " 2.6925437290397505,\n",
       " 54)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len1 = [len(p[0]) for p in data['token']]\n",
    "len2 = [len(p[1]) for p in data['token']]\n",
    "np.mean(len1), np.std(len1), np.max(len1), np.mean(len2), np.std(len2), np.max(len2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2097"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# args = {'n_src_vocab': data['fra_lang'].n_words, \n",
    "#         'n_tgt_vocab': data['eng_lang'].n_words, \n",
    "#         'len_max_seq': 65, # 65 and 54\n",
    "#         'd_word_vec': 512,\n",
    "#         'd_model': 512,\n",
    "#         'd_inner': 2048,\n",
    "#         'n_layers': 6, \n",
    "#         'n_head': 8, \n",
    "#         'd_k': 64, \n",
    "#         'd_v': 64, \n",
    "#         'dropout': 0.1,\n",
    "#         'tgt_emb_prj_weight_sharing': True,\n",
    "#         'emb_src_tgt_weight_sharing': False}\n",
    "\n",
    "class Args:\n",
    "    def __init__(self, data):\n",
    "        self.src_vocab_size = data['fra_lang'].n_words \n",
    "        self.tgt_vocab_size = data['eng_lang'].n_words \n",
    "        self.max_token_seq_len = 65 # max(65 and 54)\n",
    "        self.d_word_vec = 512\n",
    "        self.d_model = 512\n",
    "        self.d_inner_hid = 2048\n",
    "        self.n_layers = 6 \n",
    "        self.n_head = 8 \n",
    "        self.d_k = 64 \n",
    "        self.d_v = 64 \n",
    "        self.dropout = 0.1\n",
    "        self.proj_share_weight = True # proj_share_weight : tgt_emb_prj_weight_sharing\n",
    "        self.embs_share_weight = False # emb_src_tgt_weight_sharing : embs_share_weight\n",
    "\n",
    "args = Args(data)\n",
    "args.src_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Constants\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "def collate_fn(insts):\n",
    "    # if seq_pad in class then all seqs with same length\n",
    "    maxlen = max([len(x) for x in insts])\n",
    "    batch_seq = np.array([x + [Constants.PAD] * (maxlen - len(x)) for x in insts])\n",
    "    #batch_pos = np.array([[i+1 if w != Constants.PAD else 0 for i, w in enumerate(inst)] for inst in batch_seq])\n",
    "    batch_pos = np.array([[i if w != Constants.PAD else 0 for i, w in enumerate(inst, 1)] for inst in batch_seq])\n",
    "    # [[i if w != Constants.PAD else 0 for i, w in enumerate(inst, 1)] for inst in batch_seq]\n",
    "    return torch.LongTensor(batch_seq), torch.LongTensor(batch_pos)\n",
    "\n",
    "def paired_collate_fn(insts):\n",
    "    #src_insts, tgt_insts = list(zip(*insts))\n",
    "    #seq_pairs = sorted(insts, key=lambda p: len(p[0]), reverse=True)\n",
    "    src_insts, tgt_insts = zip(*insts)\n",
    "    src_insts = collate_fn(src_insts)\n",
    "    tgt_insts = collate_fn(tgt_insts)\n",
    "    return (*src_insts, *tgt_insts)\n",
    "\n",
    "class Fra2EngDatasets(Dataset):\n",
    "    def __init__(self, src, tgt):\n",
    "        self.src = src\n",
    "        self.tgt = tgt\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.src[idx], self.tgt[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 2, 77,  1,  5,  3],\n",
      "        [ 2, 75, 79, 14,  3],\n",
      "        [ 2,  1,  5,  3,  0],\n",
      "        [ 2, 77,  1,  5,  3]]), tensor([[1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 0],\n",
      "        [1, 2, 3, 4, 5]]), tensor([[ 2, 40, 43,  5,  3],\n",
      "        [ 2, 40, 44,  5,  3],\n",
      "        [ 2, 18,  7,  3,  0],\n",
      "        [ 2, 40, 45,  5,  3]]), tensor([[1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 0],\n",
      "        [1, 2, 3, 4, 5]]))\n"
     ]
    }
   ],
   "source": [
    "# filter_tokenize = data['token']\n",
    "fra_token, eng_token = zip(*filter_tokenize)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                    Fra2EngDatasets(fra_token[:100], eng_token[:100]),\n",
    "                    num_workers = 1,\n",
    "                    batch_size = 4,\n",
    "                    collate_fn = paired_collate_fn,\n",
    "                    shuffle = True,\n",
    "                    drop_last = True)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2, 77,  1,  5,  3],\n",
      "        [ 2, 75, 79, 14,  3],\n",
      "        [ 2,  1,  5,  3,  0],\n",
      "        [ 2, 77,  1,  5,  3]])\n",
      "tensor([[1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 0],\n",
      "        [1, 2, 3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "print(batch[0])\n",
    "print(batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Transformer\n",
    "transformer = Transformer(\n",
    "        args.src_vocab_size,\n",
    "        args.tgt_vocab_size,\n",
    "        args.max_token_seq_len,\n",
    "        tgt_emb_prj_weight_sharing = args.proj_share_weight,\n",
    "        emb_src_tgt_weight_sharing = args.embs_share_weight,\n",
    "        d_k = args.d_k,\n",
    "        d_v = args.d_v,\n",
    "        d_model = args.d_model,\n",
    "        d_word_vec = args.d_word_vec,\n",
    "        d_inner = args.d_inner_hid,\n",
    "        n_layers = args.n_layers,\n",
    "        n_head = args.n_head,\n",
    "        dropout = args.dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000, -0.7139,  1.5896,  ...,  0.4070,  0.7291, -0.3694],\n",
      "        [ 0.0000, -0.7342,  2.0671,  ...,  0.8151, -0.1122, -0.7192],\n",
      "        [ 0.0000, -0.5631,  1.4950,  ...,  0.7610,  0.6359, -1.0212],\n",
      "        ...,\n",
      "        [ 0.0000,  0.8169,  1.8479,  ..., -0.2909, -0.4258, -1.3035],\n",
      "        [ 0.0000,  0.0144,  0.6998,  ..., -0.2520,  0.2831, -0.8460],\n",
      "        [ 0.0000,  0.2966,  2.0965,  ...,  0.6988, -0.0550, -1.1140]],\n",
      "       grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "transformer.train()\n",
    "\n",
    "for batch in train_loader:\n",
    "    src_seq, src_pos, tgt_seq, tgt_pos = batch\n",
    "    pred = transformer(src_seq, src_pos, tgt_seq, tgt_pos)\n",
    "    print(pred)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1790])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2.9606, 2.7730, 3.1195, 2.9669, 3.3332, 2.7936, 2.8986, 3.2726, 3.0928,\n",
       "         2.9018, 2.9004, 3.0930, 2.9547, 3.3579, 3.3206, 3.1634],\n",
       "        grad_fn=<MaxBackward0>),\n",
       " tensor([1441,  470,  120,  216,  514,  428, 1040,  514, 1399,  466, 1399,  757,\n",
       "          994,  713,  495,    3]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pred.max(1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1441,  470,  120,  216,  514,  428, 1040,  514, 1399,  466, 1399,  757,\n",
       "         994,  713,  495,    3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pred[1]\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold = tgt_seq[:, 1:]\n",
    "gold.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = gold.contiguous().view(-1)\n",
    "# tensor([[17, 33,  7,  3],\n",
    "#         [18,  7,  3,  0],\n",
    "#         [40, 41,  5,  3],\n",
    "#         [49, 50,  7,  3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([17, 33,  7,  3, 18,  7,  3,  0, 40, 41,  5,  3, 49, 50,  7,  3]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.uint8))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_pad_mask = gold.ne(Constants.PAD)\n",
    "gold, non_pad_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=torch.uint8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_correct = pred.eq(gold)\n",
    "n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_correct = n_correct.masked_select(non_pad_mask).sum().item()\n",
    "n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4, 41, 82, 29, 24, 24, 15, 62, 55, 45],\n",
       "        [30, 84, 35, 60, 54, 94, 45, 66, 84, 55],\n",
       "        [40, 40, 82, 65, 73, 66, 19, 92, 47, 22],\n",
       "        [85, 19, 11, 40, 57, 58, 78, 16, 92, 97]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_bm = 3\n",
    "src_seq = torch.randint(0, 100, (4, 10))\n",
    "src_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4, 41, 82, 29, 24, 24, 15, 62, 55, 45],\n",
       "        [ 4, 41, 82, 29, 24, 24, 15, 62, 55, 45],\n",
       "        [ 4, 41, 82, 29, 24, 24, 15, 62, 55, 45],\n",
       "        [30, 84, 35, 60, 54, 94, 45, 66, 84, 55],\n",
       "        [30, 84, 35, 60, 54, 94, 45, 66, 84, 55],\n",
       "        [30, 84, 35, 60, 54, 94, 45, 66, 84, 55],\n",
       "        [40, 40, 82, 65, 73, 66, 19, 92, 47, 22],\n",
       "        [40, 40, 82, 65, 73, 66, 19, 92, 47, 22],\n",
       "        [40, 40, 82, 65, 73, 66, 19, 92, 47, 22],\n",
       "        [85, 19, 11, 40, 57, 58, 78, 16, 92, 97],\n",
       "        [85, 19, 11, 40, 57, 58, 78, 16, 92, 97],\n",
       "        [85, 19, 11, 40, 57, 58, 78, 16, 92, 97]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_seq = src_seq.repeat(1, n_bm).view(4 *3, 10)\n",
    "src_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7888,  0.5766],\n",
       "         [-0.5495,  0.1515],\n",
       "         [-1.4031, -0.8542],\n",
       "         [ 0.5637,  0.7123],\n",
       "         [-0.4461,  1.6773],\n",
       "         [ 0.5510,  0.2058],\n",
       "         [ 0.2617,  0.9290],\n",
       "         [-0.1693,  0.3658],\n",
       "         [ 0.9981, -0.7347],\n",
       "         [ 0.7736, -2.5646]],\n",
       "\n",
       "        [[-0.2205,  0.1890],\n",
       "         [-0.0167, -0.0480],\n",
       "         [-1.2016,  1.2185],\n",
       "         [ 0.2475, -0.8693],\n",
       "         [-1.8263,  1.3872],\n",
       "         [ 0.8244,  0.9413],\n",
       "         [-0.2949,  0.8623],\n",
       "         [ 0.5073, -1.4607],\n",
       "         [ 1.0888, -0.7030],\n",
       "         [-0.0861, -0.5368]],\n",
       "\n",
       "        [[ 1.0727, -0.4317],\n",
       "         [ 0.2789, -1.3457],\n",
       "         [-0.4172,  0.9617],\n",
       "         [ 0.9100, -0.0614],\n",
       "         [-0.2955,  0.8950],\n",
       "         [-1.2553,  0.1769],\n",
       "         [-1.7727,  0.8991],\n",
       "         [-0.3868,  0.5926],\n",
       "         [-0.7110,  0.3795],\n",
       "         [ 1.1802, -0.9833]],\n",
       "\n",
       "        [[ 0.3980, -0.4244],\n",
       "         [-0.2083, -0.3469],\n",
       "         [ 0.0430,  0.3725],\n",
       "         [ 0.3185,  1.1351],\n",
       "         [-0.9357,  0.7278],\n",
       "         [ 0.2260, -0.5525],\n",
       "         [ 0.0849, -1.3892],\n",
       "         [ 0.4576, -0.0839],\n",
       "         [ 0.0237, -0.1352],\n",
       "         [-0.6539,  1.3492]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_enc = torch.randn(4,10,20)\n",
    "src_enc[:, :, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 10, 20])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_h = 20\n",
    "len_s = 10\n",
    "n_inst = 4\n",
    "src_enc = src_enc.repeat(1, n_bm, 1).view(n_inst * n_bm, len_s, d_h)\n",
    "src_enc.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7888,  0.5766,  2.7153],\n",
       "         [-0.5495,  0.1515,  0.1876],\n",
       "         [-1.4031, -0.8542, -0.2365]],\n",
       "\n",
       "        [[ 0.7888,  0.5766,  2.7153],\n",
       "         [-0.5495,  0.1515,  0.1876],\n",
       "         [-1.4031, -0.8542, -0.2365]],\n",
       "\n",
       "        [[ 0.7888,  0.5766,  2.7153],\n",
       "         [-0.5495,  0.1515,  0.1876],\n",
       "         [-1.4031, -0.8542, -0.2365]],\n",
       "\n",
       "        [[-0.2205,  0.1890,  0.0079],\n",
       "         [-0.0167, -0.0480,  0.1409],\n",
       "         [-1.2016,  1.2185,  0.1445]],\n",
       "\n",
       "        [[-0.2205,  0.1890,  0.0079],\n",
       "         [-0.0167, -0.0480,  0.1409],\n",
       "         [-1.2016,  1.2185,  0.1445]],\n",
       "\n",
       "        [[-0.2205,  0.1890,  0.0079],\n",
       "         [-0.0167, -0.0480,  0.1409],\n",
       "         [-1.2016,  1.2185,  0.1445]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_enc[:6, :3, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Constants \n",
    "from beam import Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "inst_dec_beams = [Beam(n_bm, device=device) for _ in range(n_inst)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inst_dec_beams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([2, 0, 0], device='cuda:1')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst_dec_beams[0].next_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_inst_idx_list = list(range(n_inst))\n",
    "active_inst_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: 2, 3: 3}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_inst_idx_to_tensor_position_map(inst_idx_list):\n",
    "    ''' Indicate the position of an instance in a tensor. '''\n",
    "    return {inst_idx: tensor_position for tensor_position, inst_idx in enumerate(inst_idx_list)}\n",
    "\n",
    "inst_idx_to_position_map = get_inst_idx_to_tensor_position_map(active_inst_idx_list)\n",
    "inst_idx_to_position_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Decode\n",
    "\n",
    "def beam_decode_step(inst_dec_beams, len_dec_seq, src_seq, enc_output, inst_idx_to_position_map, n_bm):\n",
    "\n",
    "    ''' Decode and update beam status, and then return active beam idx '''\n",
    "\n",
    "    def prepare_beam_dec_seq(inst_dec_beams, len_dec_seq):\n",
    "        dec_partial_seq = [b.get_current_state() for b in inst_dec_beams if not b.done]\n",
    "        dec_partial_seq = torch.stack(dec_partial_seq).to(self.device)\n",
    "        dec_partial_seq = dec_partial_seq.view(-1, len_dec_seq)\n",
    "        return dec_partial_seq\n",
    "\n",
    "    def prepare_beam_dec_pos(len_dec_seq, n_active_inst, n_bm):\n",
    "        dec_partial_pos = torch.arange(1, len_dec_seq + 1, dtype=torch.long, device=self.device)\n",
    "        dec_partial_pos = dec_partial_pos.unsqueeze(0).repeat(n_active_inst * n_bm, 1)\n",
    "        return dec_partial_pos\n",
    "\n",
    "    def predict_word(dec_seq, dec_pos, src_seq, enc_output, n_active_inst, n_bm):\n",
    "        dec_output, *_ = self.model.decoder(dec_seq, dec_pos, src_seq, enc_output)\n",
    "        dec_output = dec_output[:, -1, :]  # Pick the last step: (bh * bm) * d_h\n",
    "        word_prob = F.log_softmax(self.model.tgt_word_prj(dec_output), dim=1)\n",
    "        word_prob = word_prob.view(n_active_inst, n_bm, -1)\n",
    "\n",
    "        return word_prob\n",
    "\n",
    "    def collect_active_inst_idx_list(inst_beams, word_prob, inst_idx_to_position_map):\n",
    "        active_inst_idx_list = []\n",
    "        for inst_idx, inst_position in inst_idx_to_position_map.items():\n",
    "            is_inst_complete = inst_beams[inst_idx].advance(word_prob[inst_position])\n",
    "            if not is_inst_complete:\n",
    "                active_inst_idx_list += [inst_idx]\n",
    "\n",
    "        return active_inst_idx_list\n",
    "\n",
    "    n_active_inst = len(inst_idx_to_position_map) # 4\n",
    "\n",
    "    dec_seq = prepare_beam_dec_seq(inst_dec_beams, len_dec_seq)\n",
    "    dec_pos = prepare_beam_dec_pos(len_dec_seq, n_active_inst, n_bm)\n",
    "    word_prob = predict_word(dec_seq, dec_pos, src_seq, enc_output, n_active_inst, n_bm)\n",
    "\n",
    "    # Update the beam with predicted word prob information and collect incomplete instances\n",
    "    active_inst_idx_list = collect_active_inst_idx_list(\n",
    "        inst_dec_beams, word_prob, inst_idx_to_position_map)\n",
    "\n",
    "    return active_inst_idx_list\n",
    "\n",
    "max_token_seq_len = 65\n",
    "# for len_dec_seq in range(1, max_token_seq_len + 1):\n",
    "#     print(len_dec_seq)\n",
    "#     active_inst_idx_list = beam_decode_step(\n",
    "#                     inst_dec_beams, len_dec_seq, src_seq, src_enc, inst_idx_to_position_map, n_bm)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [0],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [0]], device='cuda:1')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_active_inst = len(inst_idx_to_position_map)\n",
    "\n",
    "def prepare_beam_dec_seq(inst_dec_beams, len_dec_seq):\n",
    "    dec_partial_seq = [b.get_current_state() for b in inst_dec_beams if not b.done]\n",
    "    dec_partial_seq = torch.stack(dec_partial_seq).to(device)\n",
    "    dec_partial_seq = dec_partial_seq.view(-1, len_dec_seq)\n",
    "    return dec_partial_seq\n",
    "\n",
    "dec_seq = prepare_beam_dec_seq(inst_dec_beams, len_dec_seq)\n",
    "dec_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]], device='cuda:1')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_beam_dec_pos(len_dec_seq, n_active_inst, n_bm):\n",
    "    dec_partial_pos = torch.arange(1, len_dec_seq + 1, dtype=torch.long, device=device)\n",
    "    dec_partial_pos = dec_partial_pos.unsqueeze(0).repeat(n_active_inst * n_bm, 1)\n",
    "    return dec_partial_pos\n",
    "dec_pos = prepare_beam_dec_pos(len_dec_seq, n_active_inst, n_bm)\n",
    "dec_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.1\n",
    "n_class = pred.size(1)\n",
    "\n",
    "one_hot = torch.zeros_like(pred).scatter(1, gold.view(-1, 1), 1)\n",
    "one_hot = one_hot * (1 - eps) + (1 - one_hot) * eps / (n_class - 1)\n",
    "log_prb = F.log_softmax(pred, dim=1)\n",
    "\n",
    "non_pad_mask = gold.ne(Constants.PAD)\n",
    "loss = -(one_hot * log_prb).sum(dim=1)\n",
    "loss = loss.masked_select(non_pad_mask).sum()  # average later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10,  2,  8,  4,  9,  5,  7, 15, 18,  5,  5,  6,  2,  7, 16, 17,  2, 14,\n",
       "        16,  2,  3,  4,  8, 18,  5, 13,  5, 17, 12,  9,  1, 18,  8,  1,  4, 14,\n",
       "        12,  6,  8,  7, 18, 18, 15, 12,  9,  3,  3,  4, 10,  8,  5,  4, 17,  4,\n",
       "         6,  8,  9,  6,  3,  2, 14,  2,  9,  4, 18, 18, 16,  2,  2, 11, 14,  4,\n",
       "        18,  9,  1, 16, 16, 12, 15,  4])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = torch.randn(80, 20)\n",
    "gold = torch.randint(0, 19, (8, 10))\n",
    "gold = gold.contiguous().view(-1)\n",
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = torch.zeros_like(pred).scatter(1, gold.view(-1, 1), 1)\n",
    "print(one_hot.size())\n",
    "one_hot[:15, :15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 20])\n"
     ]
    }
   ],
   "source": [
    "log_prb = F.log_softmax(pred, dim=1)\n",
    "print(log_prb.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -(one_hot * log_prb).sum(dim=1)\n",
    "loss.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.9130, 3.6655, 3.4123, 3.6186, 3.3510, 4.3486, 3.9666, 2.4910, 4.6356,\n",
       "        3.9776, 4.2750, 5.4937, 3.3387, 4.0871, 4.2915, 3.8214, 2.2534, 2.5865,\n",
       "        1.8448, 4.1983, 2.9567, 4.2920, 2.9304, 2.0025, 3.8469, 3.8488, 3.0192,\n",
       "        4.0202, 4.5486, 2.5903, 2.8071, 3.0103, 4.1669, 3.0809, 1.9707, 4.0798,\n",
       "        2.9313, 5.6030, 2.8944, 5.1632, 4.4811, 4.1843, 4.2205, 4.4061, 3.2128,\n",
       "        3.5347, 3.8706, 0.6721, 3.8442, 2.8956, 2.9133, 2.9370, 1.4976, 4.8199,\n",
       "        3.9985, 3.0168, 4.4859, 4.4383, 2.2513, 5.1611, 4.3127, 4.6679, 4.1396,\n",
       "        3.1560, 4.1702, 2.5973, 2.3852, 3.9929, 2.6124, 2.6030, 2.7387, 5.6631,\n",
       "        2.6383, 3.8226, 3.2649, 3.4971, 4.1436, 4.3607, 1.6295, 3.1739])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.uint8)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_pad_mask = gold.ne(0)\n",
    "print(non_pad_mask.size())\n",
    "non_pad_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3000, 0.4000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7000)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss1 = torch.tensor([0.2, 0.3, 0.4, 0.5])\n",
    "non_pad_mask1 = torch.ByteTensor([0,1,1,0])\n",
    "loss1= loss1.masked_select(non_pad_mask1)\n",
    "print(loss1)\n",
    "loss1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.max(1)[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from train import Args\n",
    "from preprocess import Lang\n",
    "cp = torch.load('best_model.chkpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Transformer\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "with open('result_0326.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "model_opt = Args(data)\n",
    "\n",
    "model = Transformer(\n",
    "    model_opt.src_vocab_size,\n",
    "    model_opt.tgt_vocab_size,\n",
    "    model_opt.max_token_seq_len,\n",
    "    tgt_emb_prj_weight_sharing = model_opt.proj_share_weight,\n",
    "    emb_src_tgt_weight_sharing = model_opt.embs_share_weight,\n",
    "    d_k = model_opt.d_k,\n",
    "    d_v = model_opt.d_v,\n",
    "    d_model = model_opt.d_model,\n",
    "    d_word_vec = model_opt.d_word_vec,\n",
    "    d_inner = model_opt.d_inner_hid,\n",
    "    n_layers = model_opt.n_layers,\n",
    "    n_head = model_opt.n_head,\n",
    "    dropout = model_opt.dropout)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Trained model state loaded.\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(cp['model'])\n",
    "print('[Info] Trained model state loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "PAD = 0\n",
    "def get_non_pad_mask(seq):\n",
    "    assert seq.dim() == 2\n",
    "    ## ne if elem = pad then 0 else 1; b x sl x 1\n",
    "    return seq.ne(PAD).type(torch.float).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 2, 4, 8, 5, 6, 1],\n",
       "        [4, 5, 3, 2, 1, 0, 0],\n",
       "        [2, 3, 1, 2, 0, 0, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scc_seq = torch.LongTensor([[3,2,4,8,5,6,1], \n",
    "                            [4,5,3,2,1,0,0], \n",
    "                            [2,3,1,2,0,0,0]])\n",
    "scc_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 7, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_pad_mask = get_non_pad_mask(scc_seq)\n",
    "non_pad_mask.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]])\n"
     ]
    }
   ],
   "source": [
    "print(non_pad_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 7, 7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_attn_key_pad_mask(seq_k, seq_q):\n",
    "    ''' For masking out the padding part of key sequence. '''\n",
    "\n",
    "    # Expand to fit the shape of key query attention matrix.\n",
    "    len_q = seq_q.size(1)\n",
    "    padding_mask = seq_k.eq(PAD) # where elem = pad then 1 else 0\n",
    "    padding_mask = padding_mask.unsqueeze(1).expand(-1, len_q, -1)  # b x lq x lk\n",
    "    # here seq_k = seq_q\n",
    "    return padding_mask\n",
    "    \n",
    "slf_attn_mask = get_attn_key_pad_mask(seq_k=scc_seq, seq_q=scc_seq)\n",
    "slf_attn_mask.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 1, 1]],\n",
       "\n",
       "        [[0, 0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 1, 1, 1]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slf_attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1907, -0.1930, -1.7384, -1.3472, -0.2542, -1.0443, -2.3004],\n",
       "         [-1.2975, -1.2419,  0.9577, -0.6475,  1.0010, -0.2028,  0.4403],\n",
       "         [-0.6398,  0.4331, -1.6618, -1.5534,  0.5599, -0.8390, -0.6250],\n",
       "         [-1.8951,  0.7345, -0.3899, -0.9053,  1.4683,  0.0615, -0.0028],\n",
       "         [-0.7552,  0.2180, -0.0062, -0.3522, -1.2483,  0.0866, -0.9544],\n",
       "         [ 0.5425, -0.2690,  0.6157, -1.1469,  0.6495, -1.3331, -2.0436],\n",
       "         [-0.2885,  0.1965,  1.2770, -0.6580,  0.6872, -0.5895, -1.2989]],\n",
       "\n",
       "        [[ 0.1168,  0.0962,  0.1755, -0.2229, -0.4230,    -inf,    -inf],\n",
       "         [ 1.4319,  0.5290, -0.6110,  0.8114,  0.6045,    -inf,    -inf],\n",
       "         [ 1.0251, -0.4113, -1.3442, -1.6052, -0.5357,    -inf,    -inf],\n",
       "         [-0.9391,  2.3830,  1.1223, -1.8243,  0.2361,    -inf,    -inf],\n",
       "         [-0.3730, -0.1633, -0.6894, -0.5727,  0.4126,    -inf,    -inf],\n",
       "         [ 0.2491,  1.1800,  0.0675,  2.0645,  1.5759,    -inf,    -inf],\n",
       "         [ 0.8019, -1.0352, -0.4519, -0.1972, -1.6090,    -inf,    -inf]],\n",
       "\n",
       "        [[-0.2696, -0.6867,  0.4207, -0.5657,    -inf,    -inf,    -inf],\n",
       "         [ 0.6276,  1.3546, -1.4742, -1.4270,    -inf,    -inf,    -inf],\n",
       "         [-0.6299, -2.6592, -0.3253,  0.9474,    -inf,    -inf,    -inf],\n",
       "         [-0.2093, -0.3159,  0.7337, -0.6489,    -inf,    -inf,    -inf],\n",
       "         [-0.5427,  0.2824, -1.2187,  0.6540,    -inf,    -inf,    -inf],\n",
       "         [ 0.9542, -0.3882, -1.5637, -0.8802,    -inf,    -inf,    -inf],\n",
       "         [-1.9347, -0.6030,  0.3340, -0.6221,    -inf,    -inf,    -inf]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "attn = torch.randn(3,7,7)\n",
    "attn = attn.masked_fill(slf_attn_mask, -np.inf)\n",
    "attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1054, -1.0855, -0.2113,  0.8852, -1.1243],\n",
       "         [ 0.8511,  1.9635, -0.0993,  0.5729,  0.5146],\n",
       "         [-0.8496, -0.6644,  0.0154,  0.0218,  0.1121],\n",
       "         [-0.1432,  0.6329, -1.2499, -1.4691,  0.0487],\n",
       "         [ 0.4552,  1.5328,  0.8571,  0.0168, -0.9150],\n",
       "         [ 1.1203, -0.5750,  0.7145, -1.5010, -0.5726],\n",
       "         [ 1.4359, -0.2541,  1.7998,  1.1124, -0.7505]],\n",
       "\n",
       "        [[ 0.5389, -1.2988,  0.4234, -0.9288, -0.8077],\n",
       "         [-0.6864,  0.8567, -0.8808,  1.8583, -0.4359],\n",
       "         [ 0.0725, -0.1528, -0.2866, -0.4291, -1.0751],\n",
       "         [ 0.5324,  0.7143, -0.3355,  0.3752,  1.0411],\n",
       "         [ 0.5307, -0.4071,  0.8978,  0.9533,  0.3029],\n",
       "         [ 1.5017, -1.0790,  0.6965, -0.0104, -1.4753],\n",
       "         [ 0.5082,  0.1516,  0.1859, -0.8744,  0.9237]],\n",
       "\n",
       "        [[ 0.4984,  0.2248, -0.2131, -0.9260,  0.3960],\n",
       "         [ 0.5335, -0.7710,  0.9514, -0.6420, -0.7203],\n",
       "         [ 0.2399, -1.6857,  0.1937, -0.9144,  0.3296],\n",
       "         [ 0.8215, -0.7160, -2.5166, -0.0378,  0.8402],\n",
       "         [ 1.6729,  0.2350, -0.3991, -0.2107,  1.5395],\n",
       "         [-0.4317, -1.1466, -1.5830,  0.2735, -0.4967],\n",
       "         [-2.2341, -0.2519,  0.1826, -0.6042,  0.2747]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_output = torch.randn(3, 7, 5)\n",
    "enc_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1054, -1.0855, -0.2113,  0.8852, -1.1243],\n",
       "         [ 0.8511,  1.9635, -0.0993,  0.5729,  0.5146],\n",
       "         [-0.8496, -0.6644,  0.0154,  0.0218,  0.1121],\n",
       "         [-0.1432,  0.6329, -1.2499, -1.4691,  0.0487],\n",
       "         [ 0.4552,  1.5328,  0.8571,  0.0168, -0.9150],\n",
       "         [ 1.1203, -0.5750,  0.7145, -1.5010, -0.5726],\n",
       "         [ 1.4359, -0.2541,  1.7998,  1.1124, -0.7505]],\n",
       "\n",
       "        [[ 0.5389, -1.2988,  0.4234, -0.9288, -0.8077],\n",
       "         [-0.6864,  0.8567, -0.8808,  1.8583, -0.4359],\n",
       "         [ 0.0725, -0.1528, -0.2866, -0.4291, -1.0751],\n",
       "         [ 0.5324,  0.7143, -0.3355,  0.3752,  1.0411],\n",
       "         [ 0.5307, -0.4071,  0.8978,  0.9533,  0.3029],\n",
       "         [ 0.0000, -0.0000,  0.0000, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000, -0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.4984,  0.2248, -0.2131, -0.9260,  0.3960],\n",
       "         [ 0.5335, -0.7710,  0.9514, -0.6420, -0.7203],\n",
       "         [ 0.2399, -1.6857,  0.1937, -0.9144,  0.3296],\n",
       "         [ 0.8215, -0.7160, -2.5166, -0.0378,  0.8402],\n",
       "         [ 0.0000,  0.0000, -0.0000, -0.0000,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000,  0.0000, -0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_output *= non_pad_mask\n",
    "enc_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 6, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 0, 0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_seq = torch.LongTensor([[4,8,5,6,1,6], \n",
    "                            [3,2,1,0,0,0], \n",
    "                            [1,2,0,0,0,0]])\n",
    "\n",
    "def get_subsequent_mask(seq):\n",
    "    ''' For masking out the subsequent info. '''\n",
    "\n",
    "    sz_b, len_s = seq.size()\n",
    "    subsequent_mask = torch.triu(\n",
    "        torch.ones((len_s, len_s), device=seq.device, dtype=torch.uint8), diagonal=1)\n",
    "    subsequent_mask = subsequent_mask.unsqueeze(0).expand(sz_b, -1, -1)  # b x ls x ls\n",
    "\n",
    "    return subsequent_mask\n",
    "\n",
    "slf_attn_mask_subseq = get_subsequent_mask(tgt_seq)\n",
    "print(slf_attn_mask_subseq.size())\n",
    "slf_attn_mask_subseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 1, 1, 1]],\n",
       "\n",
       "        [[0, 0, 1, 1, 1, 1],\n",
       "         [0, 0, 1, 1, 1, 1],\n",
       "         [0, 0, 1, 1, 1, 1],\n",
       "         [0, 0, 1, 1, 1, 1],\n",
       "         [0, 0, 1, 1, 1, 1],\n",
       "         [0, 0, 1, 1, 1, 1]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slf_attn_mask_keypad = get_attn_key_pad_mask(seq_k=tgt_seq, seq_q=tgt_seq)\n",
    "slf_attn_mask_keypad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 1, 1, 1]],\n",
       "\n",
       "        [[0, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 1, 1, 1, 1],\n",
       "         [0, 0, 1, 1, 1, 1],\n",
       "         [0, 0, 1, 1, 1, 1],\n",
       "         [0, 0, 1, 1, 1, 1],\n",
       "         [0, 0, 1, 1, 1, 1]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slf_attn_mask = (slf_attn_mask_keypad + slf_attn_mask_subseq).gt(0)\n",
    "slf_attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0390,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "         [ 0.3725,  0.4847,    -inf,    -inf,    -inf,    -inf],\n",
      "         [ 0.2521,  0.9616,  0.4055,    -inf,    -inf,    -inf],\n",
      "         [ 0.5334, -0.3027,  0.1682,  0.4592,    -inf,    -inf],\n",
      "         [ 1.8542,  0.0811, -0.9784, -0.2155, -0.3622,    -inf],\n",
      "         [-0.8214,  0.1133,  0.5731, -1.6596,  1.4122,  0.3225]],\n",
      "\n",
      "        [[-0.4751,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "         [ 0.4183,  0.9962,    -inf,    -inf,    -inf,    -inf],\n",
      "         [-0.1224,  0.3569,  1.8051,    -inf,    -inf,    -inf],\n",
      "         [ 0.4057,  0.3073,  0.2014,    -inf,    -inf,    -inf],\n",
      "         [ 0.1666, -0.4830, -1.9803,    -inf,    -inf,    -inf],\n",
      "         [-1.2039,  0.1367, -1.6129,    -inf,    -inf,    -inf]],\n",
      "\n",
      "        [[-1.4043,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "         [ 0.8128,  1.8255,    -inf,    -inf,    -inf,    -inf],\n",
      "         [-1.3506,  1.1077,    -inf,    -inf,    -inf,    -inf],\n",
      "         [ 1.4936,  0.4313,    -inf,    -inf,    -inf,    -inf],\n",
      "         [ 0.0573,  0.3479,    -inf,    -inf,    -inf,    -inf],\n",
      "         [ 0.4012,  1.7974,    -inf,    -inf,    -inf,    -inf]]])\n"
     ]
    }
   ],
   "source": [
    "attn = torch.randn(3,6,6)\n",
    "attn = attn.masked_fill(slf_attn_mask, -np.inf)\n",
    "print(attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 1, 1]],\n",
       "\n",
       "        [[0, 0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 1, 1, 1]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_enc_attn_mask = get_attn_key_pad_mask(seq_k=scc_seq, seq_q=tgt_seq)\n",
    "dec_enc_attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7,  2,  7, 17, 17],\n",
      "        [19,  3, 18,  8, 10]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  2,  7, 17, 17],\n",
       "        [ 7,  2,  7, 17, 17],\n",
       "        [ 7,  2,  7, 17, 17],\n",
       "        [19,  3, 18,  8, 10],\n",
       "        [19,  3, 18,  8, 10],\n",
       "        [19,  3, 18,  8, 10]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_bm = 3 \n",
    "n_inst = 2\n",
    "src_seq = torch.randint(0, 20, (2, 5))\n",
    "print(src_seq)\n",
    "src_seq = src_seq.repeat(1, n_bm).view(n_inst * n_bm, 5)\n",
    "src_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  7, 13,  7,  4],\n",
      "        [14,  2, 11, 18,  1],\n",
      "        [15, 13,  1, 18,  7],\n",
      "        [13,  0, 10,  4,  0],\n",
      "        [10, 14, 10,  6,  0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 5])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_inst = 5\n",
    "src_seq = torch.randint(0, 20, (n_inst, 5))\n",
    "print(src_seq)\n",
    "src_seq = src_seq.repeat(1, n_bm).view(n_inst * n_bm, 5)\n",
    "src_seq.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  7, 13,  7,  4],\n",
       "        [ 1,  7, 13,  7,  4],\n",
       "        [ 1,  7, 13,  7,  4],\n",
       "        [15, 13,  1, 18,  7],\n",
       "        [15, 13,  1, 18,  7],\n",
       "        [15, 13,  1, 18,  7],\n",
       "        [10, 14, 10,  6,  0],\n",
       "        [10, 14, 10,  6,  0],\n",
       "        [10, 14, 10,  6,  0]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_seq = src_seq.view(n_inst, -1)\n",
    "ids = torch.LongTensor([0, 2, 4])\n",
    "src_seq = src_seq.index_select(0, ids)\n",
    "src_seq.view(-1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 5, 4])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_s = 5\n",
    "d_h = 4\n",
    "src_enc = torch.randn(2, 5, 4)\n",
    "src_enc = src_enc.repeat(1, n_bm, 1).view(n_inst * n_bm, len_s, d_h) # repeat : 2 x 15 x 4 ; view : 6 x 5 x 4\n",
    "src_enc.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5695,  1.0529, -0.1525, -0.8965],\n",
       "         [ 0.9586,  0.7160,  0.6085,  0.2505],\n",
       "         [-0.8403,  0.7315, -0.9570,  0.2432],\n",
       "         [-1.5587, -0.5631,  1.3815,  0.7977],\n",
       "         [ 0.5308, -0.6769,  1.8018, -0.8129]],\n",
       "\n",
       "        [[ 1.5695,  1.0529, -0.1525, -0.8965],\n",
       "         [ 0.9586,  0.7160,  0.6085,  0.2505],\n",
       "         [-0.8403,  0.7315, -0.9570,  0.2432],\n",
       "         [-1.5587, -0.5631,  1.3815,  0.7977],\n",
       "         [ 0.5308, -0.6769,  1.8018, -0.8129]],\n",
       "\n",
       "        [[ 1.5695,  1.0529, -0.1525, -0.8965],\n",
       "         [ 0.9586,  0.7160,  0.6085,  0.2505],\n",
       "         [-0.8403,  0.7315, -0.9570,  0.2432],\n",
       "         [-1.5587, -0.5631,  1.3815,  0.7977],\n",
       "         [ 0.5308, -0.6769,  1.8018, -0.8129]],\n",
       "\n",
       "        [[-0.4781,  1.1903, -0.8891, -1.2384],\n",
       "         [ 0.1979, -0.2469, -0.5289, -1.5441],\n",
       "         [-1.6505, -0.5915,  0.4779, -0.5341],\n",
       "         [ 0.9907,  0.1285, -0.2244,  0.1127],\n",
       "         [-0.0596, -1.9247, -0.4590, -0.2597]],\n",
       "\n",
       "        [[-0.4781,  1.1903, -0.8891, -1.2384],\n",
       "         [ 0.1979, -0.2469, -0.5289, -1.5441],\n",
       "         [-1.6505, -0.5915,  0.4779, -0.5341],\n",
       "         [ 0.9907,  0.1285, -0.2244,  0.1127],\n",
       "         [-0.0596, -1.9247, -0.4590, -0.2597]],\n",
       "\n",
       "        [[-0.4781,  1.1903, -0.8891, -1.2384],\n",
       "         [ 0.1979, -0.2469, -0.5289, -1.5441],\n",
       "         [-1.6505, -0.5915,  0.4779, -0.5341],\n",
       "         [ 0.9907,  0.1285, -0.2244,  0.1127],\n",
       "         [-0.0596, -1.9247, -0.4590, -0.2597]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[2],\n",
      "        [0],\n",
      "        [0]]), tensor([[2],\n",
      "        [0],\n",
      "        [0]])]\n",
      "tensor([[[2],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[2],\n",
      "         [0],\n",
      "         [0]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [0],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [0]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from beam import Beam\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "inst_dec_beams = [Beam(n_bm, device = device) for _ in range(n_inst)]\n",
    "\n",
    "def prepare_beam_dec_seq(inst_dec_beams, len_dec_seq):\n",
    "    dec_partial_seq = [b.get_current_state() for b in inst_dec_beams if not b.done]\n",
    "    print(dec_partial_seq)\n",
    "    dec_partial_seq = torch.stack(dec_partial_seq)\n",
    "    print(dec_partial_seq)\n",
    "    dec_partial_seq = dec_partial_seq.view(-1, len_dec_seq)\n",
    "    return dec_partial_seq\n",
    "\n",
    "prepare_beam_dec_seq(inst_dec_beams, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_beam_dec_pos(len_dec_seq, n_active_inst, n_bm):\n",
    "    dec_partial_pos = torch.arange(1, len_dec_seq + 1, dtype=torch.long, device=device)\n",
    "    dec_partial_pos = dec_partial_pos.unsqueeze(0).repeat(n_active_inst * n_bm, 1)\n",
    "    return dec_partial_pos\n",
    "\n",
    "dec_pos = prepare_beam_dec_pos(1, 2, n_bm)\n",
    "dec_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1397, -0.2724, -0.4226,  1.2623, -0.5551,  1.5296, -0.8335,  0.8877,\n",
      "        -0.9859])\n",
      "tensor([1.5296, 1.2623, 0.8877]) tensor([5, 3, 7])\n",
      "tensor([1.5296, 1.2623, 0.8877]) tensor([5, 3, 7])\n"
     ]
    }
   ],
   "source": [
    "flat_beam_lk = torch.randn(9)\n",
    "print(flat_beam_lk)\n",
    "best_scores, best_scores_id = flat_beam_lk.topk(3, 0, True, True) # 1st sort\n",
    "print(best_scores, best_scores_id)\n",
    "best_scores, best_scores_id = flat_beam_lk.topk(3, 0, True, True) # 2nd sort\n",
    "print(best_scores, best_scores_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_scores_id / 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[tensor([2, 0, 0], device='cuda:1'), \n",
    "  tensor([185, 677, 478], device='cuda:1'), \n",
    "  tensor([478, 170, 185], device='cuda:1'), \n",
    "  tensor([572, 739, 728], device='cuda:1'), \n",
    "  tensor([ 79,  79, 268], device='cuda:1'), \n",
    "  tensor([204, 204, 813], device='cuda:1'),\n",
    "  tensor([180, 180, 180], device='cuda:1'), \n",
    "  tensor([287, 287, 633], device='cuda:1'), \n",
    "  tensor([23, 23, 23], device='cuda:1'), \n",
    "  tensor([3, 3, 3], device='cuda:1')],  [[185, 478, 572, 79, 204, 180, 287, 23, 3]]\n",
    " \n",
    " [tensor([2, 0, 0], device='cuda:1'), \n",
    "  tensor([ 22,  79, 153], device='cuda:1'), \n",
    "  tensor([71, 185, 277], device='cuda:1'), \n",
    "  tensor([413, 186, 491], device='cuda:1'), \n",
    "  tensor([1655,  798,  186], device='cuda:1'), \n",
    "  tensor([384, 684, 684], device='cuda:1'), \n",
    "  tensor([180, 180, 180], device='cuda:1'), \n",
    "  tensor([287, 287, 287], device='cuda:1'), \n",
    "  tensor([413,   1,   1], device='cuda:1'), \n",
    "  tensor([798,   5,   5], device='cuda:1'), \n",
    "  tensor([  1,   3, 395], device='cuda:1'),\n",
    "  tensor([5, 5, 5], device='cuda:1')]] [22, 71, 413, 1655, 384, 180, 287, 413, 798, 1, 5, 3]\n",
    "\n",
    "[[tensor([0, 0, 0], device='cuda:1'), \n",
    "  tensor([0, 1, 0], device='cuda:1'), \n",
    "  tensor([0, 0, 0], device='cuda:1'), \n",
    "  tensor([0, 1,0], device='cuda:1'), \n",
    "  tensor([0, 1, 0], device='cuda:1'), \n",
    "  tensor([0, 1, 2], device='cuda:1'), \n",
    "  tensor([0, 1, 0], device='cuda:1'), \n",
    "  tensor([0, 1, 2], device='cuda:1'), \n",
    "  tensor([0, 1, 2], device='cuda:1')], \n",
    " [tensor([0, 0, 0], device='cuda:1'), tensor([0, 0, 1], device='cuda:1'), tensor([0, 0, 0], device='cuda:1'), tensor([0, 0, 0], device='cuda:1'), tensor([0, 1, 0], device='cuda:1'), tensor([0, 1, 2], device='cuda:1'), tensor([0, 1, 2], device='cuda:1'), tensor([0, 1, 2], device='cuda:1'), tensor([0, 1, 2], device='cuda:1'), tensor([0, 1, 0], device='cuda:1'), tensor([0, 1, 2], device='cuda:1')]]\n",
    "\n",
    "[[tensor([2, 0, 0], device='cuda:1'), tensor([185, 677, 478], device='cuda:1'), tensor([478, 170, 185], device='cuda:1'), tensor([572, 739, 728], device='cuda:1'), tensor([ 79,  79, 268], device='cuda:1'), tensor([204, 204, 813], device='cuda:1'),tensor([180, 180, 180], device='cuda:1'), tensor([287, 287, 633], device='cuda:1'), tensor([23, 23, 23], device='cuda:1'), tensor([3, 3, 3], device='cuda:1')], [tensor([2, 0, 0], device='cuda:1'), tensor([ 22,  79, 153], device='cuda:1'), tensor([71, 185, 277], device='cuda:1'), tensor([413, 186, 491], device='cuda:1'), tensor([1655,  798,  186], device='cuda:1'), tensor([384, 684, 684], device='cuda:1'), tensor([180, 180, 180], device='cuda:1'), tensor([287, 287, 287], device='cuda:1'), tensor([413,   1,   1], device='cuda:1'), tensor([798,   5,   5], device='cuda:1'), tensor([  1,   3, 395], device='cuda:1'),tensor([5, 5, 5], device='cuda:1'), tensor([3, 3, 3], device='cuda:1')]]\n",
    "[[tensor([0, 0, 0], device='cuda:1'), tensor([0, 1, 0], device='cuda:1'), tensor([0, 0, 0], device='cuda:1'), tensor([0, 1,0], device='cuda:1'), tensor([0, 1, 0], device='cuda:1'), tensor([0, 1, 2], device='cuda:1'), tensor([0, 1, 0], device='cuda:1'), tensor([0, 1, 2], device='cuda:1'), tensor([0, 1, 2], device='cuda:1')], [tensor([0, 0, 0], device='cuda:1'), tensor([0, 0, 1], device='cuda:1'), tensor([0, 0, 0], device='cuda:1'), tensor([0, 0, 0], device='cuda:1'), tensor([0, 1, 0], device='cuda:1'), tensor([0, 1, 2], device='cuda:1'), tensor([0, 1, 2], device='cuda:1'), tensor([0, 1, 2], device='cuda:1'), tensor([0, 1, 2], device='cuda:1'), tensor([0, 1, 0], device='cuda:1'), tensor([0, 1, 2], device='cuda:1'), tensor([0, 1, 2], device='cuda:1')]]\n",
    "\n",
    "[[[185, 478, 572, 79, 204, 180, 287, 23, 3]], \n",
    " [[22, 71, 413, 1655, 384, 180, 287, 413, 798, 1, 5, 3]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "charley",
   "language": "python",
   "name": "charley"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
