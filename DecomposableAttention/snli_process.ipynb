{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/data/ccc/dataset/snli_1.0'\n",
    "out_folder = './data_snli'\n",
    "\n",
    "label_set = set([\"neutral\", \"entailment\", \"contradiction\"])\n",
    "\n",
    "for split in [\"train\", \"dev\", \"test\"]:\n",
    "    src_out = open(os.path.join(out_folder, \"src-\" + split + \".txt\"), \"w\")\n",
    "    targ_out = open(os.path.join(out_folder, \"targ-\" + split + \".txt\"), \"w\")\n",
    "    label_out = open(os.path.join(out_folder, \"label-\" + split + \".txt\"), \"w\")\n",
    "    \n",
    "    #for line in open(os.path.join(data_folder, \"snli_1.0_\" + split + \".txt\"),\"r\"):\n",
    "    with open(os.path.join(data_folder, \"snli_1.0_\" + split + \".txt\"),\"r\") as f:\n",
    "        for line in f:\n",
    "            d = line.split(\"\\t\")\n",
    "            label = d[0].strip()\n",
    "            premise = \" \".join(d[1].replace(\"(\", \"\").replace(\")\", \"\").strip().split())\n",
    "            hypothesis = \" \".join(d[2].replace(\"(\", \"\").replace(\")\", \"\").strip().split())\n",
    "            if label in label_set:\n",
    "                src_out.write(premise + \"\\n\")\n",
    "                targ_out.write(hypothesis + \"\\n\")\n",
    "                label_out.write(label + \"\\n\")\n",
    "\n",
    "    src_out.close()\n",
    "    targ_out.close()\n",
    "    label_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A person on a horse jumps over a broken down airplane .\n",
      "A person on a horse jumps over a broken down airplane .\n",
      "A person on a horse jumps over a broken down airplane .\n",
      "Children smiling and waving at camera\n",
      "Children smiling and waving at camera\n",
      "Children smiling and waving at camera\n",
      "A boy is jumping on skateboard in the middle of a red bridge .\n",
      "A boy is jumping on skateboard in the middle of a red bridge .\n",
      "A boy is jumping on skateboard in the middle of a red bridge .\n"
     ]
    }
   ],
   "source": [
    "def show_res(filename):\n",
    "    with open(os.path.join(out_folder, filename), \"r\") as f:\n",
    "        lines = f.read().split('\\n')\n",
    "        for i in range(9):\n",
    "            print(lines[i])\n",
    "\n",
    "show_res(\"src-train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A person is training his horse for a competition .\n",
      "A person is at a diner , ordering an omelette .\n",
      "A person is outdoors , on a horse .\n",
      "They are smiling at their parents\n",
      "There are children present\n",
      "The kids are frowning\n",
      "The boy skates down the sidewalk .\n",
      "The boy does a skateboarding trick .\n",
      "The boy is wearing safety equipment .\n"
     ]
    }
   ],
   "source": [
    "show_res(\"targ-train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n",
      "contradiction\n",
      "entailment\n",
      "neutral\n",
      "entailment\n",
      "contradiction\n",
      "contradiction\n",
      "entailment\n",
      "neutral\n"
     ]
    }
   ],
   "source": [
    "show_res(\"label-train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = open('outfile.txt', \"w\")\n",
    "items = [(1,2), (3,4)]\n",
    "# items.sort()\n",
    "for v, k in items:\n",
    "    print(k, v, file=out)\n",
    "    ##print >>out, k, v\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello world\", file=open(\"foo.txt\", \"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'z']\n",
      "['b', 'x']\n",
      "['c', 'c']\n",
      "['d', 'vb']\n",
      "['e', 'n']\n"
     ]
    }
   ],
   "source": [
    "for _, (src_orig, targ_orig) in \\\n",
    "                enumerate(zip(open('foo.txt','r'), open('outfile.txt','r'))):\n",
    "    print([src_orig.strip(), targ_orig.strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.082752   0.67204   -0.14987   -0.064983   0.056491   0.40228\n",
      "  0.0027747 -0.3311    -0.30691    2.0817     0.031819   0.013643\n",
      "  0.30265    0.0071297 -0.5819    -0.2774    -0.062254   1.1451\n",
      " -0.24232    0.1235    -0.12243    0.33152   -0.006162  -0.30541\n",
      " -0.13057   -0.054601   0.037083  -0.070552   0.5893    -0.30385\n",
      "  0.2898    -0.14653   -0.27052    0.37161    0.32031   -0.29125\n",
      "  0.0052483 -0.13212   -0.052736   0.087349  -0.26668   -0.16897\n",
      "  0.015162  -0.0083746 -0.14871    0.23413   -0.20719   -0.091386\n",
      "  0.40075   -0.17223    0.18145    0.37586   -0.28682    0.37289\n",
      " -0.16185    0.18008    0.3032    -0.13216    0.18352    0.095759\n",
      "  0.094916   0.008289   0.11761    0.34046    0.03677   -0.29077\n",
      "  0.058303  -0.027814   0.082941   0.1862    -0.031494   0.27985\n",
      " -0.074412  -0.13762   -0.21866    0.18138    0.040855  -0.113\n",
      "  0.24107    0.3657    -0.27525   -0.05684    0.34872    0.011884\n",
      "  0.14517   -0.71395    0.48497    0.14807    0.62287    0.20599\n",
      "  0.58379   -0.13438    0.40207    0.18311    0.28021   -0.42349\n",
      " -0.25626    0.17715   -0.54095    0.16596   -0.036058   0.08499\n",
      " -0.64989    0.075549  -0.28831    0.40626   -0.2802     0.094062\n",
      "  0.32406    0.28437   -0.26341    0.11553    0.071918  -0.47215\n",
      " -0.18366   -0.34709    0.29964   -0.66514    0.002516  -0.42333\n",
      "  0.27512    0.36012    0.16311    0.23964   -0.05923    0.3261\n",
      "  0.20559    0.038677  -0.045816   0.089764   0.43151   -0.15954\n",
      "  0.08532   -0.26572   -0.15001    0.084286  -0.16714   -0.43004\n",
      "  0.060807   0.13121   -0.24112    0.66554    0.4453    -0.18019\n",
      " -0.13919    0.56252    0.21457   -0.46443   -0.012211   0.029988\n",
      " -0.051094  -0.20135    0.80788    0.47377   -0.057647   0.46216\n",
      "  0.16084   -0.20954   -0.05452    0.15572   -0.13712    0.12972\n",
      " -0.011936  -0.003378  -0.13595   -0.080711   0.20065    0.054056\n",
      "  0.046816   0.059539   0.046265   0.17754   -0.31094    0.28119\n",
      " -0.24355    0.085252  -0.21011   -0.19472    0.0027297 -0.46341\n",
      "  0.14789   -0.31517   -0.065939   0.036106   0.42903   -0.33759\n",
      "  0.16432    0.32568   -0.050392  -0.054297   0.24074    0.41923\n",
      "  0.13012   -0.17167   -0.37808   -0.23089   -0.019477  -0.29291\n",
      " -0.30824    0.30297   -0.22659    0.081574  -0.18516   -0.21408\n",
      "  0.40616   -0.28974    0.074174  -0.17795    0.28595   -0.039626\n",
      " -0.2339    -0.36054   -0.067503  -0.091065   0.23438   -0.0041331\n",
      "  0.003232   0.0072134  0.008697   0.21614    0.049904   0.35582\n",
      "  0.13748    0.073361   0.14166    0.2412    -0.013322   0.15613\n",
      "  0.083381   0.088146  -0.019357   0.43795    0.083961   0.45309\n",
      " -0.50489   -0.10865   -0.2527    -0.18251    0.20441    0.13319\n",
      "  0.1294     0.050594  -0.15612   -0.39543    0.12538    0.24881\n",
      " -0.1927    -0.31847   -0.12719    0.4341     0.31177   -0.0040946\n",
      " -0.2094    -0.079961   0.1161    -0.050794   0.015266  -0.2803\n",
      " -0.12486    0.23587    0.2339    -0.14023    0.028462   0.56923\n",
      " -0.1649    -0.036429   0.010051  -0.17107   -0.042608   0.044965\n",
      " -0.4393    -0.26137    0.30088   -0.060772  -0.45312   -0.19076\n",
      " -0.20288    0.27694   -0.060888   0.11944    0.62206   -0.19343\n",
      "  0.47849   -0.30113    0.059389   0.074901   0.061068  -0.4662\n",
      "  0.40054   -0.19099   -0.14331    0.018267  -0.18643    0.20709\n",
      " -0.35598    0.05338   -0.050821  -0.1918    -0.37846   -0.06589  ]\n"
     ]
    }
   ],
   "source": [
    "fname = '/data/charley/glove.840B.300d.txt'\n",
    "\n",
    "word_vecs = {}\n",
    "f = open(fname, 'r')\n",
    "for line in f:\n",
    "    d = line.split()\n",
    "    word = d[0]\n",
    "    vec = np.asarray(d[1:], dtype='float32')\n",
    "#     vec = np.array(map(float, d[1:]))\n",
    "    print(vec)\n",
    "    break\n",
    "f.close()\n",
    "# vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01624269,  0.13190901, -0.02941671, -0.01275496,  0.01108814,\n",
       "        0.07896012,  0.00054462, -0.0649888 , -0.06024076,  0.4085992 ,\n",
       "        0.00624548,  0.00267787,  0.0594046 ,  0.00139943, -0.1142162 ,\n",
       "       -0.05444849, -0.01221931,  0.22476195, -0.04756293,  0.02424076,\n",
       "       -0.02403074,  0.06507124, -0.00120949, -0.05994633, -0.02562847,\n",
       "       -0.01071717,  0.00727871, -0.01384805,  0.11566868, -0.05964013,\n",
       "        0.05688237, -0.02876113, -0.05309807,  0.07294016,  0.06287093,\n",
       "       -0.05716699,  0.00103014, -0.02593271, -0.0103511 ,  0.01714499,\n",
       "       -0.05234435, -0.03316569,  0.00297602, -0.00164378, -0.02918902,\n",
       "        0.04595539, -0.04066756, -0.01793738,  0.07865981, -0.03380556,\n",
       "        0.03561528,  0.07377437, -0.05629746,  0.0731914 , -0.03176816,\n",
       "        0.03534637,  0.05951255, -0.02594056,  0.03602158,  0.01879572,\n",
       "        0.01863026,  0.00162698,  0.02308467,  0.066826  ,  0.00721727,\n",
       "       -0.05707277,  0.0114438 , -0.00545937,  0.01627978,  0.03654761,\n",
       "       -0.00618169,  0.05492938, -0.0146057 , -0.02701226, -0.04291891,\n",
       "        0.03560154,  0.00801908, -0.02217981,  0.04731758,  0.07178015,\n",
       "       -0.05402648, -0.01115664,  0.06844728,  0.00233261,  0.02849418,\n",
       "       -0.14013517,  0.09519064,  0.0290634 ,  0.12225786,  0.04043202,\n",
       "        0.11458717, -0.02637631,  0.0789189 ,  0.03594111,  0.05500004,\n",
       "       -0.08312325, -0.0502991 ,  0.03477127, -0.10617848,  0.03257488,\n",
       "       -0.00707752,  0.01668197, -0.12756139,  0.01482887, -0.05658992,\n",
       "        0.07974132, -0.05499808,  0.01846263,  0.06360698,  0.05581657,\n",
       "       -0.05170251,  0.0226764 ,  0.01411617, -0.09267431, -0.03604906,\n",
       "       -0.06812735,  0.05881379, -0.13055468,  0.00049384, -0.08309185,\n",
       "        0.05400096,  0.07068489,  0.03201548,  0.0470369 , -0.01162575,\n",
       "        0.06400739,  0.04035351,  0.00759158, -0.00899283,  0.01761901,\n",
       "        0.08469743, -0.03131475,  0.01674674, -0.05215592, -0.02944419,\n",
       "        0.01654378, -0.03280649, -0.08440889,  0.01193529,  0.0257541 ,\n",
       "       -0.0473274 ,  0.13063319,  0.08740415, -0.03536796, -0.02732042,\n",
       "        0.11041228,  0.04211612, -0.09115902, -0.00239679,  0.00588609,\n",
       "       -0.01002881, -0.03952128,  0.1585719 ,  0.09299228, -0.01131504,\n",
       "        0.09071346,  0.03156992, -0.04112883, -0.01070127,  0.03056495,\n",
       "       -0.02691412,  0.02546164, -0.00234282, -0.00066304, -0.02668447,\n",
       "       -0.01584208,  0.03938388,  0.01061019,  0.00918911,  0.0116864 ,\n",
       "        0.00908096,  0.03484782, -0.06103177,  0.0551924 , -0.04780436,\n",
       "        0.01673339, -0.0412407 , -0.03821993,  0.00053579, -0.0909588 ,\n",
       "        0.02902807, -0.06186204, -0.01294261,  0.00708694,  0.08421065,\n",
       "       -0.06626267,  0.03225298,  0.06392495, -0.00989102, -0.0106575 ,\n",
       "        0.04725281,  0.0822871 ,  0.02554015, -0.03369565, -0.07421011,\n",
       "       -0.04531944, -0.00382297, -0.05749281, -0.06050181,  0.05946741,\n",
       "       -0.04447543,  0.01601147, -0.03634348, -0.04201994,  0.07972169,\n",
       "       -0.0568706 ,  0.01455898, -0.03492829,  0.0561267 , -0.00777785,\n",
       "       -0.04591024, -0.07076733, -0.01324959, -0.01787437,  0.04600446,\n",
       "       -0.00081125,  0.00063438,  0.00141586,  0.00170706,  0.04242428,\n",
       "        0.00979523,  0.06984089,  0.02698478,  0.01439941,  0.02780524,\n",
       "        0.0473431 , -0.00261486,  0.03064543,  0.01636615,  0.01730143,\n",
       "       -0.00379942,  0.08596148,  0.01647999,  0.08893318, -0.09910057,\n",
       "       -0.02132598, -0.04960033, -0.03582334,  0.0401219 ,  0.02614273,\n",
       "        0.02539883,  0.00993067, -0.03064347, -0.07761559,  0.02460977,\n",
       "        0.0488368 , -0.03782345, -0.06250977, -0.02496504,  0.0852058 ,\n",
       "        0.06119468, -0.00080369, -0.04110134, -0.01569487,  0.02278828,\n",
       "       -0.00996992,  0.00299643, -0.0550177 , -0.02450771,  0.04629692,\n",
       "        0.04591024, -0.02752456,  0.00558656,  0.11172932, -0.03236682,\n",
       "       -0.00715034,  0.00197283, -0.03357787, -0.00836316,  0.0088258 ,\n",
       "       -0.08622646, -0.05130209,  0.05905718, -0.01192842, -0.08893907,\n",
       "       -0.03744266, -0.03982159,  0.0543582 , -0.01195119,  0.02344386,\n",
       "        0.12209887, -0.03796673,  0.09391873, -0.05910625,  0.01165696,\n",
       "        0.01470168,  0.01198652, -0.09150644,  0.07861859, -0.0374878 ,\n",
       "       -0.0281291 ,  0.00358547, -0.03659276,  0.04064794, -0.06987229,\n",
       "        0.01047751, -0.00997522, -0.03764679, -0.0742847 , -0.01293299],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1 = vec / np.linalg.norm(vec)\n",
    "vec1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7416573867739413"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "np.linalg.norm(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7416573867739413"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "fname = \"./data_snli-train.hdf5\"\n",
    "f = h5py.File(fname, 'r')\n",
    "source = torch.from_numpy(np.array(f['source'])) - 1\n",
    "target = torch.from_numpy(np.array(f['target'])) - 1\n",
    "label = torch.from_numpy(np.array(f['label'])) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([549367, 1001])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   2,  104,  161, 2512,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source[100][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([549367])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_size = torch.from_numpy(np.array(f['label_size']))\n",
    "label_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18183])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_l = torch.from_numpy(np.array(f['source_l']))\n",
    "source_l.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_l[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17167.71875"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "549367/ 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18183])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_idx = torch.from_numpy(np.array(f['batch_idx'])) - 1\n",
    "batch_idx.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18183])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_l = torch.from_numpy(np.array(f['batch_l']))\n",
    "batch_l.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  3,  8, 15, 19, 21, 27, 28, 32])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 5, 7, 4, 2, 6, 1, 4, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_l[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "m = nn.Linear(10,2, bias=True)\n",
    "x = torch.rand(3, 10)\n",
    "y = m(x)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.bias is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  encoder(\n",
      "  (embedding): Embedding(1000, 300)\n",
      "  (input_linear): Linear(in_features=300, out_features=300, bias=False)\n",
      ")\n",
      ">>  Embedding(1000, 300)\n",
      ">>  Linear(in_features=300, out_features=300, bias=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "encoder(\n",
       "  (embedding): Embedding(1000, 300)\n",
       "  (input_linear): Linear(in_features=300, out_features=300, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, num_embeddings, embedding_size, hidden_size, para_init):\n",
    "        super(encoder, self).__init__()\n",
    "\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.para_init = para_init\n",
    "\n",
    "        self.embedding = nn.Embedding(self.num_embeddings, self.embedding_size)\n",
    "        self.input_linear = nn.Linear(\n",
    "            self.embedding_size, self.hidden_size, bias=False)  # linear transformation\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, self.para_init)\n",
    "                # m.bias.data.uniform_(-0.01, 0.01)\n",
    "\n",
    "    def forward(self, sent1, sent2):\n",
    "        '''\n",
    "               sent: batch_size x length (Long tensor)\n",
    "        '''\n",
    "        batch_size = sent1.size(0)\n",
    "        sent1 = self.embedding(sent1)\n",
    "        sent2 = self.embedding(sent2)\n",
    "\n",
    "        sent1 = sent1.view(-1, self.embedding_size)\n",
    "        sent2 = sent2.view(-1, self.embedding_size)\n",
    "\n",
    "        sent1_linear = self.input_linear(sent1).view(\n",
    "            batch_size, -1, self.hidden_size)\n",
    "        sent2_linear = self.input_linear(sent2).view(\n",
    "            batch_size, -1, self.hidden_size)\n",
    "\n",
    "        return sent1_linear, sent2_linear\n",
    "    \n",
    "enc = encoder(1000, 300, 300, 0.01)\n",
    "enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.encoder'>\n",
      "<class 'torch.nn.modules.sparse.Embedding'>\n",
      "<class 'torch.nn.modules.linear.Linear'>\n"
     ]
    }
   ],
   "source": [
    "for m in enc.modules():\n",
    "    print(type(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "charley",
   "language": "python",
   "name": "charley"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
